<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
    

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.4"/>




  <meta name="keywords" content="SMO算法,python,机器学习,算法," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.4" />


<meta name="description" content="何为支持向量机？什么是支持向量机？原理很简单：就是将分类问题转换为最优化问题；通过训练找到最合适的参数$w$，然后给出较为准确的分类结果。和Logistic归分类算法相似，但是SVM更加复杂，要大量用到拉格朗日数乘法、凸优化、非线性映射等等。不过将SVM分几个步骤来研究并不是非常复杂。">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机">
<meta property="og:url" content="http://edmund.xyz/2015/03/17/machine-learning-notes5/index.html">
<meta property="og:site_name" content="Edmund">
<meta property="og:description" content="何为支持向量机？什么是支持向量机？原理很简单：就是将分类问题转换为最优化问题；通过训练找到最合适的参数$w$，然后给出较为准确的分类结果。和Logistic归分类算法相似，但是SVM更加复杂，要大量用到拉格朗日数乘法、凸优化、非线性映射等等。不过将SVM分几个步骤来研究并不是非常复杂。">
<meta property="og:image" content="http://edmund.xyz/images/MachineLearninginAction/ml_chap6_loop1.png">
<meta property="og:image" content="http://edmund.xyz/images/MachineLearninginAction/ml_chap6_loop2.png">
<meta property="og:image" content="http://edmund.xyz/images/MachineLearninginAction/ml_chap6_figure_1.png">
<meta property="og:updated_time" content="2015-07-23T09:05:39.454Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="支持向量机">
<meta name="twitter:description" content="何为支持向量机？什么是支持向量机？原理很简单：就是将分类问题转换为最优化问题；通过训练找到最合适的参数$w$，然后给出较为准确的分类结果。和Logistic归分类算法相似，但是SVM更加复杂，要大量用到拉格朗日数乘法、凸优化、非线性映射等等。不过将SVM分几个步骤来研究并不是非常复杂。">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    sidebar: 'hide'
  };
</script>

    <title> 支持向量机 // Edmund </title>
</head>
<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">
<!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-58837095-1', 'auto');
  ga('send', 'pageview');
</script>




<div class="container one-column page-post-detail">
    <div class="headband"></div>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-logo"></i>
      </span>
      <span class="site-title">Edmund</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-categories"></i> <br />
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-tags"></i> <br />
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-archives"></i> <br />
            归档
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
<form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'wFVQJTcbGXVW6T6Evgg2','2.0.0');
</script>

<div class="site-search-toggle"></div>
    </div>
  
</nav>


        </div>
    </header>

    <main id="main" class="main">
        <div class="main-inner">
            <div id="content" class="content">
                

  <div id="posts" class="posts-expand">
    

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              支持向量机
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2015-03-17T20:05:11+08:00" content="2015-03-17">
            2015-03-17
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a href="/categories/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2015/03/17/machine-learning-notes5/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2015/03/17/machine-learning-notes5/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><h2 id="何为支持向量机？">何为支持向量机？</h2><p>什么是<code>支持向量机</code>？原理很简单：就是将分类问题转换为最优化问题；通过训练找到最合适的参数$w$，然后给出较为准确的分类结果。和Logistic归分类算法相似，但是SVM更加复杂，要大量用到拉格朗日数乘法、凸优化、非线性映射等等。不过将SVM分几个步骤来研究并不是非常复杂。</p>
<a id="more"></a>
<h2 id="建模">建模</h2><p>首先考虑线性模型：和逻辑回归方法类似，设$\mathbf{x}=[x_1, x_2, …, x_n]^T$为特征，那么训练样本就是$\mathbf{x}$所在$n$维空间中的点，于是一个线性分类器的目的就是要在$n$维的数据空间中找到一个超平面$$\mathbf{w}^T\mathbf{x}+b=0$$将两种类别的样本分开。其中，$\mathbf{w}=[w_1, w_2, …, w_n]^T$、$b$为超平面系数。</p>
<p>在逻辑回归中，是用0和1作为分类标签，而这里将改用-1和+1，这么做是为了便于后面数学上的处理（可以通过统一的公式来表示距离，而不必担心数据到底是属于-1还是+1类）。<br>$$<br>y=g(z)=<br>\begin{cases}<br>1, &amp; \text{if $z&gt;0$} \\<br>-1, &amp; \text{if $z&lt;0$},<br>\end{cases}<br>$$其中，$z=f(\mathbf{x})=\mathbf{w}^T\mathbf{x}+b$。</p>
<p>在逻辑回归中，是用Sigmoid函数处理$z&gt;0$和$z&lt;0$的，那么SVM是怎么处理的呢？这里将超平面向两边“平移”做平行的超平面：$\mathbf{w}^T\mathbf{x}+b=\pm\hat{\gamma}$。那么，样本$\left(x^{(i)}, y^{(i)}\right)$刚好落在平行的超平面上时，我们可以得到<br>$$<br>\hat{\gamma}^{(i)}=|\mathbf{w}^T\mathbf{x^{(i)}}+b|=y^{(i)}(\mathbf{w}^T\mathbf{x^{(i)}}+b),<br>$$这里的$\hat{\gamma}^{(i)}$为样本$\left(x^{(i)}, y^{(i)}\right)$的函数间隔。</p>
<p><strong>定义1</strong> 对于所有样本$\left(x^{(i)}, y^{(i)}\right)$，其全局<code>函数间隔</code>为<br>$$<br>\hat{\gamma}=\min_{i=1,2,…,m}\hat{\gamma}^{(i)}.<br>$$</p>
<p><strong>备注</strong>：为什么要找最小值？因为找到满足$z&gt;0$和$z<0$且$\hat{\gamma}$最小的那个样本，那么其他样本一定满足$z>0$和$z&lt;0$。</0$且$\hat{\gamma}$最小的那个样本，那么其他样本一定满足$z></p>
<p>样本$\left(x^{(i)}, y^{(i)}\right)$到超平面$\mathbf{w}^T\mathbf{x}+b=0$的距离公式可以表示为$\gamma^{(i)}=\frac{|\mathbf{w}^T\mathbf{x}^{(i)}+b|}{\parallel\mathbf{w}\parallel}$（利用投影或者转换为拉格朗日数乘法求解），于是有：</p>
<p><strong>定义2</strong> 对于所有样本$\left(x^{(i)}, y^{(i)}\right)$的<code>几何间隔</code>定义为<br>$$<br>\gamma=\min_{i=1,2,…,m}\gamma^{(i)}=\frac{\hat{\gamma}}{\parallel\mathbf{w}\parallel}.<br>$$</p>
<p>有了几何距离的概念，分类器的求解问题就可以转换为：找到最优的$w$使得几何距离$\gamma$最大。这也就是说，分类器（超平面）将两种类别“分得越开”，这样的分类器是我们需要找到的。该描述可以形式化的表示为：<br>$$<br>\begin{align}<br>&amp;\max\ \frac{\hat{\gamma}}{\parallel\mathbf{w}\parallel}\\<br>&amp;\mathrm{s}.\mathrm{t}.\ \ y^{(i)}(\mathbf{w}^T\mathbf{x^{(i)}}+b)\geqslant\hat{\gamma},\ i=1,2,…,m.<br>\end{align}<br>$$这里通常取$\hat{\gamma}=1$，因为通过$\parallel\mathbf{w’}\parallel=\parallel\mathbf{w/\sqrt{\hat{\gamma}}}\parallel$即可转换为上式，只是差一个系数而已。此外，求$\frac{1}{\parallel\mathbf{w}\parallel}$的最大值相当于求$\frac{1}{2}\parallel\mathbf{w}\parallel^2$的最小值，于是上式可改写为：<br>$$<br>\begin{align}<br>&amp;\min_{\mathrm{w}}\ \frac{1}{2}\parallel\mathbf{w}\parallel^2\\<br>&amp;\mathrm{s}.\mathrm{t}.\ \ 1-y^{(i)}(\mathbf{w}^T\mathbf{x^{(i)}}+b)\leqslant0,\ i=1,2,…,m.<br>\end{align}<br>$$这是典型的二次规划问题（目标函数是二次的，约束条件是线性的）。</p>
<hr>
<h2 id="最优化问题的求解">最优化问题的求解</h2><p><strong>方法1</strong>：使用QP（Quadratic Programming）优化包求解[4]。</p>
<p><strong>方法2</strong>：拉格朗日求解法</p>
<p>对于一般的非线性规划问题<br>$$<br>\begin{align}<br>\min_{\mathrm{w}}\ &amp;f(\mathrm{w})\\<br>\mathrm{s}.\mathrm{t}.\ &amp;g_i(\mathrm{w})\leqslant0,\ i=1,2,…,k\\<br>&amp;h_i(\mathrm{w})=0,\ i=1,2,…,l.<br>\end{align}<br>$$</p>
<p>引入拉格朗日函数：$\mathcal{L}(\mathrm{w},\alpha,\beta)=f(\mathrm{w})+\sum_{i=1}^k\alpha_ig_i(\mathrm{w})+\sum_j^l\beta_jh_j(\mathrm{w})$，其中$\alpha_i\geqslant0$。</p>
<p>可以得到<br>$$<br>\theta_\mathcal{P}(\mathrm{w})=\max_{\alpha,\beta:\ \alpha_i\geqslant0}\mathcal{L}(\mathrm{w},\alpha,\beta)=f(x).<br>$$</p>
<p>于是原问题的最优值$p^*$可以表示为：</p>
<p>$$<br>p^*=\min_\mathrm{w}\theta_\mathcal{P}(w)=\min_\mathrm{w}\max_{\alpha,\beta:\ \alpha_i\geqslant0}\mathcal{L}(\mathrm{w},\alpha,\beta).<br>$$</p>
<p><strong>方法3</strong>：对偶问题的最优解</p>
<p>上式的拉格朗日<code>对偶问题</code>的最优值$d^*$可以表示为：</p>
<p>$$<br>d^*=\max_{\alpha,\beta:\ \alpha_i\geqslant0}\theta_D(w)=\max_{\alpha,\beta:\ \alpha_i\geqslant0}\min_\mathrm{w}\mathcal{L}(\mathrm{w},\alpha,\beta).<br>$$</p>
<p>很容易得到：$d^*\leqslant p^*$。当且仅当满足<code>KKT（Karush-Kuhn-Tucker）条件</code>时，取$d^*=p^*$。</p>
<p>KKT定理就是要求在取最优值$x^*$和$\alpha^*,\beta^*$时，拉格朗日函数$\mathcal{L}$对于各个变量的偏导数为0，而且要求$\alpha_i^*c_i(x^*)=0,\ i=1,2,…,k$。</p>
<p><strong>备注</strong>：关于拉格朗日求解法及其对偶问题的推导、讲解和证明见[6]。</p>
<hr>
<h2 id="SMO_算法">SMO 算法</h2><p>对于之前给出的二次规划问题，假设满足KKT条件的，那么我们可以用对偶问题来求解最优值：</p>
<p>$$<br>d^*=\max_{\alpha:\ \alpha_i\geqslant0}\min_{\mathrm{w},\ b}\mathcal{L}(\alpha,\mathrm{w},b).<br>$$</p>
<p>先求$\min_{\mathrm{w},\ b}\mathcal{L}(\alpha,\mathrm{w},b)$：</p>
<p>$$<br>\frac{\partial\mathcal{L}}{\partial\mathrm{w}}=0\ \Rightarrow\ \mathrm{w}=\sum_{i=1}^m\alpha_i y^{(i)} \mathrm{x}^{(i)},<br>$$</p>
<p>$$<br>\frac{\partial\mathcal{L}}{\partial b}=0 \Rightarrow\ \sum_{i=1}^m \alpha_i y^{(i)}=0.<br>$$</p>
<p>将两式代入$\mathcal{L}(\alpha,\mathrm{w},b)=\frac{1}{2}\parallel\mathbf{w}\parallel^2-\sum_{i=1}^m\alpha_i\left(1-y^{(i)}(\mathbf{w}^T\mathbf{x^{(i)}}+b)\right)$中，化简得到：</p>
<p>$$<br>\mathcal{L}(\alpha,\mathrm{w},b)=\sum_{i=1}^m\alpha_i-\frac{1}{2}\sum\alpha_i\alpha_j y^{(i)} y^{(j)}{\mathrm{x}^{(i)}}^T\mathrm{x}^{(j)}.<br>$$</p>
<p>从上面的式子得到：<br>$$<br>\begin{align}<br>\max_\alpha\ &amp;\sum\alpha_i-\frac{1}{2}\sum\alpha_i\alpha_j y^{(i)} y^{(j)}{\mathrm{x}^{(i)}}^T\mathrm{x}^{(j)}\\<br>\mathrm{s}.\mathrm{t}.\ &amp;0\leqslant\alpha_i\leqslant C,\ i=1,2,…,m\\<br>&amp;\sum \alpha_i y^{(i)}=0<br>\end{align}<br>$$其中$C$是松弛变量，许有些数据点“噪声”处于分隔面的 错误一侧，这么做可以防止无解以及解的范围太小。这里求解$\alpha$需要用到<code>SMO算法</code>。</p>
<p><strong>SMO算法</strong></p>
<p>1996年，John Platt发布了一个称为SMO（Sequential Minimal Optimization）的强大算法，用于训练SVM。SMO算法看起来很复杂，但就其本质而言只是对坐标下降法的改进。对于这样一个问题：<br>$$<br>\max_\alpha g(\alpha_1,\alpha_2,…,\alpha_m),<br>$$通过坐标上升法，每次只调整一个变量$\alpha_i$的值，而其他变量的值固定不变，不断循环迭代进而得到最优值。一般情况下，都是按照$i=1,2,…,m$的顺序，但是通过更改优化顺序，可以更快地收敛到最优值。流程如图：<br><img src="/images/MachineLearninginAction/ml_chap6_loop1.png" alt="Cdescent"></p>
<p>SMO和坐标上升法不同之处在于，SMO一次迭代需要优化两个变量：$\alpha_i$和$\alpha_j$。这是因为有$\sum \alpha_i y^{(i)}=0$这样一个约束，一次迭代只改变一个变量是不可能的，它可以通过别“常量”算出来。SMO之所以高效就是因为在固定其他参数后，对一个参数优化过程很高效（对一个参数的优化可以通过解析求解，而不是迭代。虽然对一个参数的一次最小优化不可能保证其结果就是所优化的拉格朗日乘子的最终结果，但会使目标函数向极小值迈进一步，这样对所有的乘子做最小优化，直到所有满足KKT条件时，目标函数达到最小）[8]。SMO的流程如图：<br><img src="/images/MachineLearninginAction/ml_chap6_loop2.png" alt="SMO"></p>
<p>在给出SMO算法之前，先对数据进行处理，并给出辅助函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []; labelMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        lineArr = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        dataMat.append([float(lineArr[<span class="number">0</span>]), float(lineArr[<span class="number">1</span>])])</span><br><span class="line">        labelMat.append(float(lineArr[<span class="number">2</span>]))</span><br><span class="line">    <span class="keyword">return</span> dataMat,labelMat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 任选一个不等于i的j</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJrand</span><span class="params">(i,m)</span>:</span></span><br><span class="line">    j = i</span><br><span class="line">    <span class="keyword">while</span> (j==i):</span><br><span class="line">        j = int(random.uniform(<span class="number">0</span>,m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对alpha_j进行约束</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clipAlpha</span><span class="params">(aj,H,L)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> aj &gt; H:</span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L &gt; aj:</span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br></pre></td></tr></table></figure>
<p><strong>简化版SMO</strong></p>
<p>伪代码：</p>
<p>创建一个$\alpha$向量并将其初始化为0向量<br>当迭代次数小于最大迭代次数时（外循环）<br>　　对数据集中的每个数据向量（内循环）<br>　　　　如果该数据向量可以被优化<br>　　　　　　随机选择另外一个数据向量<br>　　　　　　同时优化这两个向量<br>　　　　如果两个向量都不能被优化，退出内循环<br>　　如果所有向量都没被优化，增加迭代数目，继续下一次循环</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoSimple</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter)</span>:</span></span><br><span class="line"><span class="comment"># C松弛变量  toler容忍极限值  maxIter最大循环次数</span></span><br><span class="line">    dataMatrix = mat(dataMatIn) <span class="comment"># 列表转换为矩阵</span></span><br><span class="line">    labelMat = mat(classLabels).transpose()</span><br><span class="line">    b = <span class="number">0</span></span><br><span class="line">    m,n = shape(dataMatrix) <span class="comment"># m个训练样本，n个特征</span></span><br><span class="line">    alphas = mat(zeros((m,<span class="number">1</span>))) <span class="comment"># 拉格朗日乘子</span></span><br><span class="line">    iter = <span class="number">0</span> <span class="comment"># 没有任何一对alpha改变的情况下遍历数据集的次数</span></span><br><span class="line">    <span class="keyword">while</span> (iter &lt; maxIter):</span><br><span class="line">    <span class="comment"># 只有数据集上遍历maxIter次，且不再发生任何alpha修改之后，程序才会停止并退出循环</span></span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            fXi = float(multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)) + b</span><br><span class="line">            <span class="comment"># ui = (sum y^(i)*alpha_i*x^(i))^T*x^(i) + b</span></span><br><span class="line">            Ei = fXi - float(labelMat[i])  <span class="comment"># Ei = ui - y^(i)</span></span><br><span class="line">            <span class="keyword">if</span> ((labelMat[i]*Ei &lt; -toler) <span class="keyword">and</span> (alphas[i] &lt; C)) \</span><br><span class="line">                <span class="keyword">or</span> ((labelMat[i]*Ei &gt; toler) <span class="keyword">and</span> (alphas[i] &gt; <span class="number">0</span>)): <span class="comment"># 该点在边界附近</span></span><br><span class="line">                j = selectJrand(i,m) <span class="comment"># 任选一个j，j != i</span></span><br><span class="line">                fXj = float(multiply(alphas,labelMat).T \</span><br><span class="line">                    *(dataMatrix*dataMatrix[j,:].T)) + b</span><br><span class="line">                Ej = fXj - float(labelMat[j])</span><br><span class="line">                alphaIold = alphas[i].copy()</span><br><span class="line">                alphaJold = alphas[j].copy()</span><br><span class="line">                <span class="keyword">if</span> (labelMat[i] != labelMat[j]): <span class="comment"># y^(i)是否和y^(j)同号，给出不同的约束</span></span><br><span class="line">                    L = max(<span class="number">0</span>, alphas[j] - alphas[i])</span><br><span class="line">                    H = min(C, C + alphas[j] - alphas[i])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    L = max(<span class="number">0</span>, alphas[j] + alphas[i] - C)</span><br><span class="line">                    H = min(C, alphas[j] + alphas[i])</span><br><span class="line">                <span class="keyword">if</span> L==H: <span class="comment"># L和H相等，不做任何改变</span></span><br><span class="line">                    <span class="keyword">print</span> <span class="string">"L==H"</span>; <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># eta是alpha_j代入W中，然后求导得到的K11,K22,K12</span></span><br><span class="line">                eta = <span class="number">2.0</span> * dataMatrix[i,:]*dataMatrix[j,:].T - \</span><br><span class="line">                    dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T</span><br><span class="line">                <span class="keyword">if</span> eta &gt;= <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">print</span> <span class="string">"eta&gt;=0"</span>; <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 更新alpha_j，eta&lt;0则目标函数是正定，可直线约束方向上求得最小值</span></span><br><span class="line">                alphas[j] -= labelMat[j]*(Ei - Ej)/eta</span><br><span class="line">                <span class="comment"># 对alpha_j约束</span></span><br><span class="line">                alphas[j] = clipAlpha(alphas[j],H,L)</span><br><span class="line">                <span class="keyword">if</span> (abs(alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>): <span class="comment"># alpha_j几乎没有变</span></span><br><span class="line">                    <span class="keyword">print</span> <span class="string">"j not moving enough"</span>; <span class="keyword">continue</span></span><br><span class="line">                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])</span><br><span class="line">                <span class="comment"># y^(i)*y^(j)*(alpha_j - alpha_jnew)，</span></span><br><span class="line">                <span class="comment">#有的教程中用s = y^(i)*y^(j)，alpha_i和j相反方向改变</span></span><br><span class="line">                <span class="comment"># 根据KKT条件调整b</span></span><br><span class="line">                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:] \</span><br><span class="line">                    *dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)* \</span><br><span class="line">                    *dataMatrix[i,:]*dataMatrix[j,:].T</span><br><span class="line">                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:] \</span><br><span class="line">                    *dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold) \</span><br><span class="line">                    *dataMatrix[j,:]*dataMatrix[j,:].T</span><br><span class="line">                <span class="keyword">if</span> (<span class="number">0</span> &lt; alphas[i]) <span class="keyword">and</span> (C &gt; alphas[i]):</span><br><span class="line">                    b = b1</span><br><span class="line">                <span class="keyword">elif</span> (<span class="number">0</span> &lt; alphas[j]) <span class="keyword">and</span> (C &gt; alphas[j]):</span><br><span class="line">                    b = b2</span><br><span class="line">                <span class="keyword">else</span>: b = (b1 + b2)/<span class="number">2.0</span></span><br><span class="line">                alphaPairsChanged += <span class="number">1</span></span><br><span class="line">                <span class="keyword">print</span> <span class="string">"iter: %d i:%d, pairs changed %d"</span> % (iter,i,alphaPairsChanged)</span><br><span class="line">        <span class="keyword">if</span> (alphaPairsChanged == <span class="number">0</span>):</span><br><span class="line">            iter += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            iter = <span class="number">0</span> <span class="comment"># alpha_i和alpha_j改变了循环次数置零</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</span><br><span class="line">    <span class="keyword">return</span> b,alphas</span><br></pre></td></tr></table></figure>
<p><em>运行结果</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> svm</span><br><span class="line">&gt;&gt;&gt;data, lab = svm.loadDataSet(<span class="string">'testSet.txt'</span>)</span><br><span class="line">&gt;&gt;&gt;b, alphas = svm.smoSimple(data, lab, <span class="number">0.6</span>, <span class="number">0.001</span>, <span class="number">40</span>)</span><br><span class="line">...</span><br><span class="line">iter: <span class="number">7</span> i:<span class="number">17</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">7</span> i:<span class="number">52</span>, pairs changed <span class="number">2</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">6</span> i:<span class="number">17</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">10</span> i:<span class="number">55</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">36</span> i:<span class="number">29</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">36</span> i:<span class="number">55</span>, pairs changed <span class="number">2</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">5</span> i:<span class="number">52</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">1</span> i:<span class="number">29</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">1</span> i:<span class="number">17</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">6</span> i:<span class="number">52</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">1</span> i:<span class="number">17</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">3</span> i:<span class="number">55</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">1</span> i:<span class="number">23</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">1</span> i:<span class="number">52</span>, pairs changed <span class="number">2</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">16</span> i:<span class="number">29</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">iter: <span class="number">9</span> i:<span class="number">55</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line"><span class="prompt">... </span>    <span class="keyword">if</span> alphas[i]&gt;<span class="number">0.0</span>: <span class="keyword">print</span> i,<span class="string">':'</span>,data[i],lab[i]</span><br><span class="line"><span class="number">17</span> : [<span class="number">4.658191</span>, <span class="number">3.507396</span>] -<span class="number">1.0</span></span><br><span class="line"><span class="number">29</span> : [<span class="number">3.457096</span>, -<span class="number">0.082216</span>] -<span class="number">1.0</span></span><br><span class="line"><span class="number">52</span> : [<span class="number">2.893743</span>, -<span class="number">1.643468</span>] -<span class="number">1.0</span></span><br><span class="line"><span class="number">55</span> : [<span class="number">6.080573</span>, <span class="number">0.418886</span>] <span class="number">1.0</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="完整版SMO">完整版SMO</h2><p>Platt SMO算法是通过一个外循环来选择第一个$\alpha$值的，并且其选择过程会在两种方式之间进行交替：一种方式是在所有数据集上进行单遍扫描，另一种方式则是在非边界（$\alpha\neq0$且$\alpha\neq C$）$\alpha$中实现单遍扫描。在选择第一个$\alpha$值后，算法会通过一个内循环来选择第二个$\alpha$值。在优化过程中，会通过最大化步长的方式来获得第二个$\alpha$值。</p>
<p>完整版和简化版SMO的区别在于选取$\alpha_i$和$\alpha_j$的方式。[8]中有详细的SMO步骤，我不在赘述，这里直接给出代码和详细注释。</p>
<p><strong>预处理和计算</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span> <span class="comment"># 没啥实质作用，就是减少函数需要的输入。这样会不会耗内存？</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler)</span>:</span> <span class="comment"># 初始参数 </span></span><br><span class="line">        self.X = dataMatIn</span><br><span class="line">        self.labelMat = classLabels</span><br><span class="line">        self.C = C</span><br><span class="line">        self.tol = toler</span><br><span class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">        self.alphas = mat(zeros((self.m,<span class="number">1</span>)))</span><br><span class="line">        self.eCache = mat(zeros((self.m,<span class="number">2</span>)))</span><br><span class="line">        <span class="comment"># eCache的第一列给出的是eCache是否有效的标志位，而第二列给出的是实际的E值</span></span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算u_k和E_k值并返回</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcEk</span><span class="params">(oS, k)</span>:</span></span><br><span class="line">    fXk = float(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b) <span class="comment"># u_k</span></span><br><span class="line">    Ek = fXk - float(oS.labelMat[k]) <span class="comment"># E_k</span></span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectJ</span><span class="params">(i, oS, Ei)</span>:</span></span><br><span class="line"><span class="comment"># 用于选择alpha_j</span></span><br><span class="line">    maxK = -<span class="number">1</span></span><br><span class="line">    maxDeltaE = <span class="number">0</span></span><br><span class="line">    Ej = <span class="number">0</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>,Ei] <span class="comment"># 设置Ei有效</span></span><br><span class="line">    <span class="comment"># nonzero()构建非零表头，返回非零Ei对应的alpha值</span></span><br><span class="line">    validEcacheList = nonzero(oS.eCache[:,<span class="number">0</span>].A)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> (len(validEcacheList)) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</span><br><span class="line">        <span class="comment">#loop through valid Ecache values and find the one that maximizes delta E</span></span><br><span class="line">            <span class="keyword">if</span> k == i: <span class="keyword">continue</span> <span class="comment"># k=i则不计算，节约时间</span></span><br><span class="line">            Ek = calcEk(oS, k)</span><br><span class="line">            deltaE = abs(Ei - Ek)</span><br><span class="line">            <span class="keyword">if</span> (deltaE &gt; maxDeltaE): <span class="comment"># 选择具有最大步长的Ej</span></span><br><span class="line">                maxK = k</span><br><span class="line">                maxDeltaE = deltaE</span><br><span class="line">                Ej = Ek</span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># 第一次循环随机选择一个j值</span></span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="keyword">return</span> j, Ej</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateEk</span><span class="params">(oS, k)</span>:</span> <span class="comment"># alpha_k改变之后更新E_k</span></span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>,Ek]</span><br></pre></td></tr></table></figure>
<p><strong>内循环</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">innerL</span><span class="params">(i, oS)</span>:</span></span><br><span class="line">    Ei = calcEk(oS, i)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> ((oS.labelMat[i]*Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> \</span><br><span class="line">        ((oS.labelMat[i]*Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">    <span class="comment"># 检查是否违反KKT条件的alpha</span></span><br><span class="line">    <span class="comment"># 满足KKT条件</span></span><br><span class="line">    <span class="comment"># 1) yi*f(i)&gt;=1并且alpha=0 (两条间隔线外)</span></span><br><span class="line">    <span class="comment"># 2) yi*f(i)=1 并且0&lt;alpha&lt;C (两条间隔线上)</span></span><br><span class="line">    <span class="comment"># 3) yi*f(i)&lt;=1并且alpha=C (两条间隔线内部)</span></span><br><span class="line">    <span class="comment"># 不满足KKT条件  </span></span><br><span class="line">    <span class="comment"># 1) y[i]*E_i&lt;0或yi*f(i)&lt;1，但是alpha&lt;C (应该alpha=C)   </span></span><br><span class="line">    <span class="comment"># 2) y[i]*E_i&gt;0或yi*f(i)&gt;1，但是alpha&gt;0 (应该alpha=0)  </span></span><br><span class="line">    <span class="comment"># 3) y[i]*E_i=0或yi*f(i)=1，但是alpha=C (0&lt;alpha&lt;C)</span></span><br><span class="line"></span><br><span class="line">        j,Ej = selectJ(i, oS, Ei)</span><br><span class="line">        <span class="comment"># 选择最大化迭代步长|Ei-Ej|的第二个乘子</span></span><br><span class="line"></span><br><span class="line">        alphaIold = oS.alphas[i].copy()</span><br><span class="line">        alphaJold = oS.alphas[j].copy()</span><br><span class="line">        <span class="keyword">if</span> (oS.labelMat[i] != oS.labelMat[j]):</span><br><span class="line">        <span class="comment"># 给出[0, C]x[0, C]内的alpha_j上下限</span></span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = max(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</span><br><span class="line">            H = min(oS.C, oS.alphas[j] + oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L==H: <span class="keyword">print</span> <span class="string">"L==H"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        eta = <span class="number">2.0</span> * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>: <span class="keyword">print</span> <span class="string">"eta&gt;=0"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta <span class="comment"># 找到目标最大的alpha_j</span></span><br><span class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)</span><br><span class="line">        updateEk(oS, j) <span class="comment"># 更新E_j</span></span><br><span class="line">        <span class="keyword">if</span> (abs(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>): <span class="comment"># alpha_j没怎么改变</span></span><br><span class="line">            <span class="keyword">print</span> <span class="string">"j not moving enough"</span>; <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])</span><br><span class="line">        <span class="comment"># 更新alpha_i，相反方向</span></span><br><span class="line">        updateEk(oS, i) <span class="comment"># 更新E_i</span></span><br><span class="line">        <span class="comment"># 更新截距，使满足KKT条件</span></span><br><span class="line">        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] \</span><br><span class="line">            - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]</span><br><span class="line">        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j] \</span><br><span class="line">            - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]): oS.b = b1</span><br><span class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]): oS.b = b2</span><br><span class="line">        <span class="keyword">else</span>: oS.b = (b1 + b2)/<span class="number">2.0</span> <span class="comment"># 都满足求平均值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p><strong>外循环</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smoP</span><span class="params">(dataMatIn, classLabels, C, toler, maxIter,kTup=<span class="params">(<span class="string">'lin'</span>, <span class="number">0</span>)</span>)</span>:</span></span><br><span class="line">    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup) <span class="comment"># 初始化</span></span><br><span class="line">    iter = <span class="number">0</span></span><br><span class="line">    entireSet = <span class="keyword">True</span>; alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> (iter &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)):</span><br><span class="line">    <span class="comment"># 循环条件：小于循环次数，或者alpha有改变</span></span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> entireSet:</span><br><span class="line">        <span class="comment"># 当某一次遍历发现没有非边界数据样本得到调整时</span></span><br><span class="line">        <span class="comment"># 遍历整个训练集，以检验是否整个集合都满足KKT条件</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(oS.m):</span><br><span class="line">                alphaPairsChanged += innerL(i,oS) <span class="comment"># alpha_i,alpha_j有变化则加1</span></span><br><span class="line">                <span class="keyword">print</span> <span class="string">"fullSet, iter: %d i:%d, pairs changed %d"</span> \</span><br><span class="line">                    % (iter,i,alphaPairsChanged)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 当有边界样本时（两条间隔线上），选取边界上样本的alpha_i</span></span><br><span class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">                <span class="keyword">print</span> <span class="string">"non-bound, iter: %d i:%d, pairs changed %d"</span> \</span><br><span class="line">                    % (iter,i,alphaPairsChanged)</span><br><span class="line">        iter += <span class="number">1</span> <span class="comment"># 循环次数+1</span></span><br><span class="line">        <span class="keyword">if</span> entireSet: entireSet = <span class="keyword">False</span> <span class="comment"># 遍历了所有样本，且没有边界上的样本</span></span><br><span class="line">        <span class="keyword">elif</span> (alphaPairsChanged == <span class="number">0</span>): entireSet = <span class="keyword">True</span>  </span><br><span class="line">        <span class="keyword">print</span> <span class="string">"iteration number: %d"</span> % iter</span><br><span class="line">    <span class="keyword">return</span> oS.b,oS.alphas</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="核函数">核函数</h2><p>从一开始对线性分类器的建模到后来的分析，我们都是用的线性空间，所有向量的加法与数乘都可以通过线性叠加来表示，其向量的内积$&lt;\mathrm{x},\mathrm{y}&gt;$可以表示为：<br>$$(x_1,x_2,…,x_n)^T\cdot(y_1,y_2,…,y_n)^T=x_1y_1+x_2y_2+…+x_ny_n.$$</p>
<p>对于非线性空间中的点$\xi$和$\zeta$可以通过映射$\phi(\cdot)$来表示成线性空间中的点$\phi(\xi)$和$\phi(\zeta)$。$\phi(\xi)$和$\phi(\zeta)$是可以使用内积计算的。这里就定义$\kappa(\cdot,\cdot)$为<code>核函数</code>，目的是表示映射过的点的内积：$$\kappa(\xi,\zeta)=\phi(\xi)\cdot\phi(\zeta)=\phi(\xi)^T\phi(\zeta).$$于是就可以将之前所有的$\mathrm{x}$，$\mathrm{x}^{(k)}$和$\mathrm{x}^{(k)}\cdot\mathrm{x}$都换成：$\phi(\mathrm{x})$，$\phi(\mathrm{x})^{(k)}$和$\kappa(\mathrm{x}^{(k)},\mathrm{x})$，其中，$\mathrm{x}$是非线性空间中的点。如果$\phi(\mathrm{x})$被划分好，就表明$\mathrm{x}$被划分好。</p>
<p>关于核函数是否有效（证明略去），有以下充要定理：<br>$\kappa$是有效的核函数 &lt;=&gt; 核函数矩阵$K$是对称半正定的。<br>其中，$K_{i,j}=\kappa(\mathrm{x}^{(i)},\mathrm{x}^{(jk)})$。</p>
<p>在不同的空间中的映射有不同的核函数，我们一般都可以通过推导求得。对于几种常见的核函数，前人已经帮我们做好了推导工作，我们到时候直接用就可以了。</p>
<p><em>线性核函数</em><br>$$\kappa(\xi,\zeta)=\xi\cdot\zeta$$</p>
<p><em>多项式核函数</em><br>$$\kappa(\xi,\zeta)=(\xi\cdot\zeta+1)^d$$</p>
<p><em>高斯核函数</em><br>$$\kappa(\xi,\zeta)=exp\left\{-\frac{\parallel\xi-\zeta\parallel^2}{2\sigma^2}\right\}$$其中，$\sigma$是用户定义的用于确定到达率或者说函数值跌落到0的速度参数。</p>
<p>以下是核函数代码，引入了新的变量kTup</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernelTrans</span><span class="params">(X, A, kTup)</span>:</span></span><br><span class="line">    m,n = shape(X)</span><br><span class="line">    K = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>]==<span class="string">'lin'</span>:</span><br><span class="line">        K = X * A.T <span class="comment"># 线性核函数</span></span><br><span class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>]==<span class="string">'rbf'</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">            deltaRow = X[j,:] - A</span><br><span class="line">            K[j] = deltaRow*deltaRow.T</span><br><span class="line">        K = exp(K/(-<span class="number">1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>)) <span class="comment"># 高斯核</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> NameError(<span class="string">'That Kernel is not recognized'</span>)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">optStruct</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataMatIn, classLabels, C, toler, kTup)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.m):</span><br><span class="line">            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="运行结果">运行结果</h2><p><strong>训练</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;&gt; </span><span class="keyword">from</span> svm <span class="keyword">import</span> *</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>dataArr,labelArr = loadDataSet(<span class="string">'testSet.txt'</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>b, alphas = smoP(dataArr, labelArr, <span class="number">0.6</span>, <span class="number">0.001</span>, <span class="number">40</span>)</span><br><span class="line">fullSet, iter: <span class="number">0</span> i:<span class="number">0</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">fullSet, iter: <span class="number">0</span> i:<span class="number">44</span>, pairs changed <span class="number">11</span></span><br><span class="line">L==H</span><br><span class="line">...</span><br><span class="line">iteration number: <span class="number">1</span></span><br><span class="line">non-bound, iter: <span class="number">1</span> i:<span class="number">4</span>, pairs changed <span class="number">1</span></span><br><span class="line">...</span><br><span class="line">j <span class="keyword">not</span> moving enough</span><br><span class="line">non-bound, iter: <span class="number">1</span> i:<span class="number">10</span>, pairs changed <span class="number">3</span></span><br><span class="line">...</span><br><span class="line">iteration number: <span class="number">3</span></span><br><span class="line">...</span><br><span class="line">j <span class="keyword">not</span> moving enough</span><br><span class="line">fullSet, iter: <span class="number">3</span> i:<span class="number">54</span>, pairs changed <span class="number">0</span></span><br><span class="line">j <span class="keyword">not</span> moving enough</span><br><span class="line">fullSet, iter: <span class="number">3</span> i:<span class="number">55</span>, pairs changed <span class="number">0</span></span><br><span class="line">...</span><br><span class="line">fullSet, iter: <span class="number">3</span> i:<span class="number">99</span>, pairs changed <span class="number">0</span></span><br><span class="line">iteration number: <span class="number">4</span></span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>b</span><br><span class="line">matrix([[-<span class="number">3.28463005</span>]])</span><br></pre></td></tr></table></figure></p>
<p><strong>生成$\mathrm{w}$</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcWs</span><span class="params">(alphas,dataArr,classLabels)</span>:</span></span><br><span class="line">    X = mat(dataArr); labelMat = mat(classLabels).transpose()</span><br><span class="line">    m,n = shape(X)</span><br><span class="line">    w = zeros((n,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        w += multiply(alphas[i]*labelMat[i],X[i,:].T)</span><br><span class="line">    <span class="keyword">return</span> w</span><br></pre></td></tr></table></figure></p>
<p><em>结果</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;&gt; </span>ws=calcWs(alphas,dataArr,labelArr)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>ws</span><br><span class="line">array([[ <span class="number">0.74764704</span>],</span><br><span class="line">       [-<span class="number">0.17895243</span>]])</span><br><span class="line"></span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>datMat=mat(dataArr)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>datMat[<span class="number">0</span>]*mat(ws)+b</span><br><span class="line">matrix([[-<span class="number">0.98996178</span>]])</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>labelArr[<span class="number">0</span>]</span><br><span class="line">-<span class="number">1.0</span></span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>datMat[<span class="number">6</span>]*mat(ws)+b</span><br><span class="line">matrix([[ <span class="number">2.78682539</span>]])</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>labelArr[<span class="number">6</span>]</span><br><span class="line"><span class="number">1.0</span></span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>datMat[<span class="number">10</span>]*mat(ws)+b</span><br><span class="line">matrix([[-<span class="number">1.</span>]])</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>labelArr[<span class="number">10</span>]</span><br><span class="line">-<span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p><strong>作图</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showSVM</span><span class="params">(svm)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> svm.X.shape[<span class="number">1</span>] != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Sorry! I can not draw because the dimension of your data is not 2!"</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="comment"># draw all samples</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(svm.m):</span><br><span class="line">        <span class="keyword">if</span> svm.labelMat[i] == -<span class="number">1</span>:</span><br><span class="line">            plt.plot(svm.X[i, <span class="number">0</span>], svm.X[i, <span class="number">1</span>], <span class="string">'or'</span>)</span><br><span class="line">        <span class="keyword">elif</span> svm.labelMat[i] == <span class="number">1</span>:</span><br><span class="line">            plt.plot(svm.X[i, <span class="number">0</span>], svm.X[i, <span class="number">1</span>], <span class="string">'ob'</span>)</span><br><span class="line">    <span class="comment"># mark support vectors</span></span><br><span class="line">    supportVectorsIndex = nonzero(svm.alphas.A &gt; <span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> supportVectorsIndex:</span><br><span class="line">        plt.plot(svm.X[i, <span class="number">0</span>], svm.X[i, <span class="number">1</span>], <span class="string">'oy'</span>)</span><br><span class="line">    <span class="comment"># draw the classify line</span></span><br><span class="line">    w = zeros((<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> supportVectorsIndex:</span><br><span class="line">        w += multiply(svm.alphas[i] * svm.labelMat[i], svm.X[i, :].T)</span><br><span class="line">    min_x = min(svm.X[:, <span class="number">0</span>])[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    max_x = max(svm.X[:, <span class="number">0</span>])[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    y_min_x = float(-svm.b - w[<span class="number">0</span>] * min_x) / w[<span class="number">1</span>]</span><br><span class="line">    y_max_x = float(-svm.b - w[<span class="number">0</span>] * max_x) / w[<span class="number">1</span>]</span><br><span class="line">    plt.plot([min_x, max_x], [y_min_x, y_max_x], <span class="string">'-g'</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
<p><em>作图结果</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="prompt">&gt;&gt;&gt; </span>svmClassifier = smoP(dataArr, labelArr, <span class="number">0.6</span>, <span class="number">0.001</span>, <span class="number">40</span>)</span><br><span class="line"><span class="prompt">&gt;&gt;&gt; </span>showSVM(svmClassifier)</span><br></pre></td></tr></table></figure></p>
<p><img src="/images/MachineLearninginAction/ml_chap6_figure_1.png" alt="Res1"></p>
<p><strong>利用核函数进行分类的径向基测试</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> svm <span class="keyword">import</span> *</span><br><span class="line">k1=<span class="number">1.3</span></span><br><span class="line">dataArr,labelArr = loadDataSet(<span class="string">'testSetRBF.txt'</span>)</span><br><span class="line">b,alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">'rbf'</span>, k1))</span><br><span class="line"><span class="comment"># C=200</span></span><br><span class="line">datMat = mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">svInd = nonzero(alphas.A&gt;<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">sVs = datMat[svInd]</span><br><span class="line">labelSV = labelMat[svInd];</span><br><span class="line"><span class="keyword">print</span> <span class="string">"there are %d Support Vectors"</span> % shape(sVs)[<span class="number">0</span>]</span><br><span class="line">m,n = shape(datMat)</span><br><span class="line">errorCount = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">'rbf'</span>, k1))</span><br><span class="line">    predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">    <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"the training error rate is: %f"</span> % (float(errorCount)/m)</span><br><span class="line">dataArr,labelArr = loadDataSet(<span class="string">'testSetRBF2.txt'</span>)</span><br><span class="line">errorCount = <span class="number">0</span></span><br><span class="line">datMat=mat(dataArr); labelMat = mat(labelArr).transpose()</span><br><span class="line">m,n = shape(datMat)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">'rbf'</span>, k1))</span><br><span class="line">    predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">    <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): errorCount += <span class="number">1</span>    </span><br><span class="line"><span class="keyword">print</span> <span class="string">"the test error rate is: %f"</span> % (float(errorCount)/m)</span><br></pre></td></tr></table></figure></p>
<p><em>运行结果</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iteration number: <span class="number">6</span></span><br><span class="line">there are <span class="number">27</span> Support Vectors</span><br><span class="line">the training error rate <span class="keyword">is</span>: <span class="number">0.030000</span></span><br><span class="line">the test error rate <span class="keyword">is</span>: <span class="number">0.030000</span></span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="参考文献">参考文献</h2><p>[1] P. Harrington, Machine Learning in Action[M]. Greenwich, CT, USA: Manning, 2012.<br>[2] <a href="http://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="external">http://en.wikipedia.org/wiki/Support_vector_machine</a><br>[3] <a href="http://blog.csdn.net/macyang/article/details/38782399" target="_blank" rel="external">http://blog.csdn.net/macyang/article/details/38782399</a><br>[4] <a href="http://www.numerical.rl.ac.uk/people/nimg/qp/qp.html" target="_blank" rel="external">http://www.numerical.rl.ac.uk/people/nimg/qp/qp.html</a><br>[5] Platt J. Fast Training of Support Vector Machines Using Sequential Minimal Optimization[J]. <em>Advances in kernel methods—support vector learning</em>, 1999.<br>[6] <a href="http://www.cnblogs.com/90zeng/p/Lagrange_duality.html" target="_blank" rel="external">http://www.cnblogs.com/90zeng/p/Lagrange_duality.html</a><br>[7] <a href="http://blog.csdn.net/techq/article/details/6171688" target="_blank" rel="external">http://blog.csdn.net/techq/article/details/6171688</a><br>[8] <a href="http://blog.csdn.net/zouxy09/article/details/17292011" target="_blank" rel="external">http://blog.csdn.net/zouxy09/article/details/17292011</a></p>
</span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/SMO算法/" rel="tag">#SMO算法</a>
          
            <a href="/tags/python/" rel="tag">#python</a>
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/算法/" rel="tag">#算法</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/03/25/machine-learning-notes6/" rel="prev">AdaBoost元算法</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/03/10/machine-learning-notes4/" rel="next">Logistic回归分类</a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


            </div>

            

            
              <div class="comments" id="comments">
                
                  <div class="ds-thread" data-thread-key="2015/03/17/machine-learning-notes5/"
                       data-title="支持向量机" data-url="http://edmund.xyz/2015/03/17/machine-learning-notes5/">
                  </div>
                
              </div>
            
        </div>

        
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/ed.png" alt="Edmund" itemprop="image"/>
          <p class="site-author-name" itemprop="name">Edmund</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">10</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">2</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">18</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ycliuxinwei" target="_blank">GitHub</a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://cn.linkedin.com/pub/xinwei-liu/74/2a9/136" target="_blank">Linkedin</a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#何为支持向量机？"><span class="nav-number">1.</span> <span class="nav-text">何为支持向量机？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#建模"><span class="nav-number">2.</span> <span class="nav-text">建模</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最优化问题的求解"><span class="nav-number">3.</span> <span class="nav-text">最优化问题的求解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SMO_算法"><span class="nav-number">4.</span> <span class="nav-text">SMO 算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#完整版SMO"><span class="nav-number">5.</span> <span class="nav-text">完整版SMO</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#核函数"><span class="nav-number">6.</span> <span class="nav-text">核函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#运行结果"><span class="nav-number">7.</span> <span class="nav-text">运行结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">8.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
        <div class="footer-inner">
            <div class="copyright" >
  
  &copy; &nbsp;  2014 - 
  <span itemprop="copyrightYear">2015</span>
  <span class="with-love">
    <i class="icon-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Edmund</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



        </div>
    </footer>

    <div class="back-to-top"></div>
</div>

<script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"edmund"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.4"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.4"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.4" id="motion.global"></script>



  <script type="text/javascript" src="/js/search-toggle.js"></script>


  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.4" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;
          var self = this;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      $(indicator).velocity('stop').velocity({
        opacity: action === 'show' ? 0.4 : 0
      }, { duration: 100 });
    }

  });
</script>


  <script type="text/javascript" id="sidebar.nav">
    $(document).ready(function () {
      var html = $('html');

      $('.sidebar-nav li').on('click', function () {
        var item = $(this);
        var activeTabClassName = 'sidebar-nav-active';
        var activePanelClassName = 'sidebar-panel-active';
        if (item.hasClass(activeTabClassName)) {
          return;
        }

        var currentTarget = $('.' + activePanelClassName);
        var target = $('.' + item.data('target'));

        currentTarget.velocity('transition.slideUpOut', 200, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', 200)
            .addClass(activePanelClassName);
        });

        item.siblings().removeClass(activeTabClassName);
        item.addClass(activeTabClassName);
      });

      $('.post-toc a').on('click', function (e) {
        e.preventDefault();
        var offset = $(escapeSelector(this.getAttribute('href'))).offset().top;
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        });
      });

      // Expand sidebar on post detail page by default, when post has a toc.
      var $tocContent = $('.post-toc-content');
      if (isDesktop() && CONFIG.sidebar === 'post') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          displaySidebar();
        }
      }
    });
  </script>




<script type="text/javascript">
    $(document).ready(function () {
        if (CONFIG.sidebar === 'always') {
            displaySidebar();
        }
    });
</script>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>







<!-- lazyload -->
<script type="text/javascript" src="/js/lazyload.js"></script>
<script type="text/javascript">
    jQuery(function () {
        jQuery("#posts img").lazyload({
            placeholder: "/images/loading.gif",
            effect: "fadeIn"
        });
    });
</script>
</body>
</html>
